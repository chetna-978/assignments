{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3e30ad",
   "metadata": {},
   "source": [
    "1. What is the function of a summation junction of a neuron? What is threshold activation\n",
    "function?\n",
    "2. What is a step function? What is the difference of step function with threshold function?\n",
    "3. Explain the McCulloch–Pitts model of neuron.\n",
    "4. Explain the ADALINE network model.\n",
    "5. What is the constraint of a simple perceptron? Why it may fail with a real-world data set?\n",
    "6. What is linearly inseparable problem? What is the role of the hidden layer?\n",
    "7. Explain XOR problem in case of a simple perceptron.\n",
    "8. Design a multi-layer perceptron to implement A XOR B.\n",
    "9. Explain the single-layer feed forward architecture of ANN.\n",
    "10. Explain the competitive network architecture of ANN.\n",
    "11. Consider a multi-layer feed forward neural network. Enumerate and explain steps in the\n",
    "backpropagation algorithm used to train the network.\n",
    "12. What are the advantages and disadvantages of neural networks?\n",
    "13. Write short notes on any two of the following:\n",
    "\n",
    "a. Biological neuron\n",
    "b. ReLU function\n",
    "c. Single-layer feed forward ANN\n",
    "d. Gradient descent\n",
    "e. Recurrent networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e93ff1",
   "metadata": {},
   "source": [
    "Ans 1:\n",
    "\n",
    "Function of a summation junction of a neuron: The summation junction (often termed as the aggregation function or simply the summation function) of a neuron takes all the input signals, multiplies them by their corresponding weights, and sums them up.\n",
    "\n",
    "Threshold activation function: The threshold activation function is used to determine the output of a neuron based on whether the aggregated input (after the summation) crosses a certain threshold. If the summed value exceeds the threshold, the neuron fires and produces an output; otherwise, it remains silent.\n",
    "\n",
    "Ans 2:\n",
    "\n",
    "Step function: It's an activation function that outputs a binary value, typically 0 or 1. If the input crosses a certain point (threshold), the output jumps from one value to another.\n",
    "\n",
    "Difference between step function and threshold function: Both functions involve a threshold, but while the step function immediately jumps from one value to another at the threshold, the threshold activation function gradually changes the output based on the magnitude of the input.\n",
    "\n",
    "Ans 3:\n",
    "McCulloch–Pitts model of neuron is a simplified mathematical model that captures the essence of how biological neurons might work. It considers inputs with associated weights, an aggregation step, and a threshold activation function.\n",
    "\n",
    "Ans 4:\n",
    "ADALINE (Adaptive Linear Neuron) is a type of neural network that, unlike the perceptron, uses a linear activation function and adjusts its weights using a linear function of the net input.\n",
    "\n",
    "Ans 5:\n",
    "The constraint of a simple perceptron is that it can only classify linearly separable data. It might fail with real-world datasets that are not linearly separable, leading to misclassifications.\n",
    "\n",
    "Ans 6:\n",
    "Linearly inseparable problem refers to data that cannot be separated by a straight line in a 2D plane. The role of the hidden layer in neural networks is to capture and transform the input into a higher-dimensional space where the data might become linearly separable.\n",
    "\n",
    "Ans 7:\n",
    "The XOR problem arises because a simple perceptron (with one layer) cannot represent XOR's non-linear decision boundary. XOR is not linearly separable, so a single perceptron will always misclassify some inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e94eb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#Ans:8\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# XOR dataset\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([0, 1, 1, 0])\n",
    "\n",
    "# Multi-layer perceptron model\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(2,), activation='logistic', max_iter=1000)\n",
    "mlp.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "predictions = mlp.predict(X)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca2d7ae",
   "metadata": {},
   "source": [
    "Ans 9:\n",
    "Single-layer feed-forward ANN consists of input and output layers without any hidden layers. Data flows only in one direction, from input to output, without any feedback loops.\n",
    "\n",
    "Ans 10:\n",
    "In a competitive network, neurons compete to become active (or 'win') based on their input. Typically, only one neuron becomes active, representing the 'winner-takes-all' behavior.\n",
    "\n",
    "Ans 11:\n",
    "Backpropagation in multi-layer networks involves:\n",
    "\n",
    "Forward pass: Compute the output for a given input.\n",
    "Compute the error between the predicted output and the actual output.\n",
    "Backward pass: Update weights starting from the output layer and moving backward to the input layer, using the error to adjust weights.\n",
    "\n",
    "Ans 12:\n",
    "Advantages: Neural networks can model complex patterns, generalize well to unseen data, and can handle noisy data.\n",
    "Disadvantages: They require large amounts of data, are computationally intensive, and can be hard to interpret.\n",
    "\n",
    "Ans 13:\n",
    "\n",
    "a. Biological neuron:\n",
    "A biological neuron is the fundamental unit of the nervous system, responsible for transmitting electrical and chemical signals. Structurally, it consists of a cell body, dendrites (receiving inputs), and an axon (transmitting output). When the sum of the inputs surpasses a certain threshold, the neuron fires an action potential, sending a signal to other connected neurons. The complex interconnection and dynamic firing patterns of these neurons form the basis of neural networks' inspiration in machine learning.\n",
    "\n",
    "b. ReLU function (Rectified Linear Unit):\n",
    "ReLU, short for Rectified Linear Unit, is a widely used activation function in neural networks.Mathematically, it's defined as \n",
    "f(x)=max(0,x). In simpler terms, it returns the input directly if it's positive; otherwise, it returns zero. One of ReLU's primary advantages is that it introduces non-linearity to the model without affecting the positive values, allowing the network to learn from positive signals and ignore negative ones. This activation function has been instrumental in training deep neural networks, promoting faster convergence compared to other activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f182ca12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
