{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b677053",
   "metadata": {},
   "source": [
    "1. What exactly is a feature? Give an example to illustrate your point.\n",
    "2. What are the various circumstances in which feature construction is required?\n",
    "3. Describe how nominal variables are encoded.\n",
    "\n",
    "4. Describe how numeric features are converted to categorical features.\n",
    "\n",
    "5. Describe the feature selection wrapper approach. State the advantages and disadvantages of this\n",
    "approach?\n",
    "\n",
    "6. When is a feature considered irrelevant? What can be said to quantify it?\n",
    "\n",
    "7. When is a function considered redundant? What criteria are used to identify features that could\n",
    "be redundant?\n",
    "\n",
    "8. What are the various distance measurements used to determine feature similarity?\n",
    "\n",
    "9. State difference between Euclidean and Manhattan distances?\n",
    "\n",
    "10. Distinguish between feature transformation and feature selection.\n",
    "\n",
    "11. Make brief notes on any two of the following:\n",
    "\n",
    "a.SVD (Standard Variable Diameter)\n",
    "\n",
    "b. Collection of features using a hybrid approach\n",
    "\n",
    "c. The width of the silhouette\n",
    "\n",
    "d. Receiver operating characteristic curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250e964f",
   "metadata": {},
   "source": [
    "Ans 1:\n",
    "A feature in machine learning is a measurable property or characteristic of the data that serves as an input for modeling or analysis. For instance, in a dataset about houses, features could include the number of bedrooms, square footage, location, and age of the house.\n",
    "\n",
    "Ans 2:\n",
    "Feature construction becomes necessary in several situations such as:\n",
    "\n",
    "When existing features are insufficient to capture data patterns.\n",
    "To create composite features representing interactions between original ones.\n",
    "To transform features to align better with a modeling algorithm's requirements.\n",
    "\n",
    "Ans 3:\n",
    "Nominal variables, which lack inherent order, can be encoded through techniques like:\n",
    "\n",
    "One-Hot Encoding: Representing each category as a binary vector.\n",
    "Label Encoding: Assigning unique integer labels to categories.\n",
    "\n",
    "Ans 4:\n",
    "Numeric features can be transformed into categorical ones using methods like binning or discretization, which involve grouping continuous values into discrete intervals or categories.\n",
    "\n",
    "Ans 5:\n",
    "The feature selection wrapper approach involves evaluating different feature subsets using a specific algorithm and selecting the subset optimizing a performance criterion. While it can pinpoint predictive features, it may be computationally intensive.\n",
    "\n",
    "Ans 6:\n",
    "A feature is deemed irrelevant when it doesn't contribute significantly to the model's predictive power. This lack of contribution can be quantified using techniques like feature importance scores or correlation analysis.\n",
    "\n",
    "Ans 7:\n",
    "A redundant feature is one that conveys redundant or duplicate information already captured by other features. Features that exhibit high correlation or similarity can be considered redundant and may be identified through correlation matrices or feature importance analysis.\n",
    "\n",
    "Ans 8:\n",
    "Distance measurements such as Euclidean distance, Manhattan distance, and cosine similarity are used to determine feature similarity and dissimilarity between data points.\n",
    "\n",
    "Ans 9:\n",
    "Euclidean distance measures the straight-line distance between two points in Euclidean space, while Manhattan distance computes the distance between two points as the sum of their absolute differences along each dimension.\n",
    "\n",
    "Ans 10:\n",
    "Feature transformation involves transforming existing features into a new set of features, often to meet modeling assumptions, whereas feature selection entails choosing a subset of the most relevant features to use in the model, potentially improving model performance and interpretability.\n",
    "\n",
    "Ans 11a:\n",
    "SVD, or Singular Value Decomposition, is a matrix factorization method used for dimensionality reduction and data compression, often employed in techniques like Principal Component Analysis (PCA).\n",
    "\n",
    "Ans 11b:\n",
    "The collection of features using a hybrid approach involves combining multiple feature extraction and selection methods, leveraging their strengths to capture diverse and relevant information from the data.\n",
    "\n",
    "Ans 11c:\n",
    "The width of the silhouette is a metric used to measure the separation distance between the clusters in a clustering algorithm. It quantifies how similar an object is to its own cluster compared to other clusters. A silhouette width close to +1 indicates that the object is well-clustered, a value around 0 indicates overlapping clusters, and a value close to -1 indicates that the object may have been assigned to the wrong cluster.\n",
    "\n",
    "Ans 11d:\n",
    "The Receiver Operating Characteristic (ROC) curve is a graphical representation that illustrates the performance of a binary classification model at various threshold settings. It plots the True Positive Rate (Sensitivity) against the False Positive Rate (1 - Specificity) for different threshold values. The area under the ROC curve (AUC-ROC) provides a single metric to evaluate the model's discriminative ability, with a higher AUC indicating better performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc915ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
