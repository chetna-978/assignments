{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f77380d",
   "metadata": {},
   "source": [
    "1. What are the advantages of a CNN over a fully connected DNN for image classification?\n",
    "2. Consider a CNN composed of three convolutional layers, each with 3 × 3 kernels, a stride of\n",
    "2, and &quot;same&quot; padding. The lowest layer outputs 100 feature maps, the middle one outputs\n",
    "200, and the top one outputs 400. The input images are RGB images of 200 × 300 pixels.\n",
    "What is the total number of parameters in the CNN? If we are using 32-bit floats, at least how much\n",
    "RAM will this network require when making a prediction for a single instance? What about when\n",
    "training on a mini-batch of 50 images?\n",
    "3. If your GPU runs out of memory while training a CNN, what are five things you could try to\n",
    "solve the problem?\n",
    "4. Why would you want to add a max pooling layer rather than a convolutional layer with the\n",
    "same stride?\n",
    "5. When would you want to add a local response normalization layer?\n",
    "6. Can you name the main innovations in AlexNet, compared to LeNet-5? What about the main\n",
    "innovations in GoogLeNet, ResNet, SENet, and Xception?\n",
    "7. What is a fully convolutional network? How can you convert a dense layer into a\n",
    "convolutional layer?\n",
    "8. What is the main technical difficulty of semantic segmentation?\n",
    "9. Build your own CNN from scratch and try to achieve the highest possible accuracy on MNIST.\n",
    "10. Use transfer learning for large image classification, going through these steps:\n",
    "a. Create a training set containing at least 100 images per class. For example, you could\n",
    "classify your own pictures based on the location (beach, mountain, city, etc.), or\n",
    "alternatively you can use an existing dataset (e.g., from TensorFlow Datasets).\n",
    "b. Split it into a training set, a validation set, and a test set.\n",
    "c. Build the input pipeline, including the appropriate preprocessing operations, and\n",
    "optionally add data augmentation.\n",
    "d. Fine-tune a pretrained model on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e78f60",
   "metadata": {},
   "source": [
    "Ans 1:\n",
    "\n",
    "Advantages of CNN over a fully connected DNN for image classification:\n",
    "Parameter Efficiency: CNNs use shared weights (kernels) which significantly reduces the number of parameters compared to fully connected layers.\n",
    "Spatial Hierarchies: CNNs are designed to recognize local patterns and gradually combine them to recognize larger, more complex patterns in the image.\n",
    "Translation Invariance: Due to pooling layers, CNNs can recognize patterns regardless of their position in the image.\n",
    "Reduced Overfitting: With fewer parameters and the use of techniques like pooling and dropout, CNNs often generalize better to unseen data.\n",
    "\n",
    "Ans 2:\n",
    "\n",
    "To calculate the parameters:\n",
    "For the first convolutional layer: \n",
    "(\n",
    "3\n",
    "×\n",
    "3\n",
    "×\n",
    "3\n",
    ")\n",
    "×\n",
    "100\n",
    "(3×3×3)×100\n",
    "For the second convolutional layer: \n",
    "(\n",
    "3\n",
    "×\n",
    "3\n",
    "×\n",
    "100\n",
    ")\n",
    "×\n",
    "200\n",
    "(3×3×100)×200\n",
    "For the third convolutional layer: \n",
    "(\n",
    "3\n",
    "×\n",
    "3\n",
    "×\n",
    "200\n",
    ")\n",
    "×\n",
    "400\n",
    "(3×3×200)×400\n",
    "Add these together for the total number of parameters.\n",
    "To calculate RAM:\n",
    "For inference: Total parameters * 32 bits\n",
    "For a mini-batch of 50 images during training: (Total parameters * 32 bits) * 50\n",
    "\n",
    "Ans 3:\n",
    "\n",
    "Five things to try if GPU runs out of memory:\n",
    "Reduce the batch size.\n",
    "Use a model with fewer parameters.\n",
    "Reduce the image resolution.\n",
    "Use mixed precision training (if supported).\n",
    "Use model parallelism across multiple GPUs.\n",
    "\n",
    "Ans 4:\n",
    "\n",
    "A max pooling layer reduces the spatial dimensions of the feature map, thus reducing the computational complexity. Using a convolutional layer with the same stride would retain the spatial dimensions, requiring more computations and potentially leading to overfitting.\n",
    "\n",
    "Ans 5:\n",
    "\n",
    "Local Response Normalization (LRN) is useful when you want to enhance the response of one neuron relative to its neighbors. It's often used in architectures where the output of one convolutional layer is fed into another.\n",
    "\n",
    "Ans 6:\n",
    "\n",
    "Innovations in AlexNet compared to LeNet-5:\n",
    "Use of ReLU activation.\n",
    "Use of dropout for regularization.\n",
    "GPU acceleration for training.\n",
    "GoogLeNet introduced inception modules.\n",
    "ResNet introduced residual connections.\n",
    "SENet introduced squeeze-and-excitation blocks.\n",
    "Xception introduced depthwise separable convolutions.\n",
    "\n",
    "Ans 7:\n",
    "\n",
    "A fully convolutional network (FCN) is a neural network architecture that only contains convolutional and pooling layers, without any fully connected layers. To convert a dense layer into a convolutional layer, you'd replace the dense layer with a convolutional layer with the same number of filters, kernel size, and stride.\n",
    "\n",
    "Ans 8:\n",
    "\n",
    "The main technical difficulty of semantic segmentation is preserving spatial information while predicting dense pixel-wise labels. Overlapping objects, occlusions, and variations in object size and shape make it challenging to produce accurate segmentation masks.\n",
    "\n",
    "Ans 9:\n",
    "\n",
    "Building a CNN for MNIST requires constructing a simple architecture with convolutional layers, pooling layers, and fully connected layers. Achieving high accuracy would involve experimenting with different architectures, optimizing hyperparameters, and potentially using techniques like dropout for regularization.\n",
    "\n",
    "Ans 10:\n",
    "\n",
    "The steps you provided outline the process of transfer learning for image classification. This involves:\n",
    "a. Gathering or preparing a dataset.\n",
    "b. Splitting the dataset into training, validation, and test sets.\n",
    "c. Preprocessing the data and potentially adding data augmentation.\n",
    "d. Fine-tuning a pretrained model on the new dataset, potentially replacing the final layers to match the number of classes in the new dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38f659c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
