{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7736b8d",
   "metadata": {},
   "source": [
    "1. Describe the structure of an artificial neuron. How is it similar to a biological neuron? What\n",
    "are its main components?\n",
    "2. What are the different types of activation functions popularly used? Explain each of them.\n",
    "\n",
    "a. Explain, in details, Rosenblatt’s perceptron model. How can a set of data be classified using a\n",
    "simple perceptron?\n",
    "\n",
    "b. Use a simple perceptron with weights w 0 , w 1 , and w 2\n",
    "as −1, 2, and 1, respectively, to classify\n",
    "data points (3, 4); (5, 2); (1, −3); (−8, −3); (−3, 0).\n",
    "c. Explain the basic structure of a multi-layer perceptron. Explain how it can solve the XOR\n",
    "problem.\n",
    "\n",
    "3. What is artificial neural network (ANN)? Explain some of the salient highlights in the\n",
    "different architectural options for ANN.\n",
    "\n",
    "4. Explain the learning process of an ANN. Explain, with example, the challenge in assigning\n",
    "synaptic weights for the interconnection between neurons? How can this challenge be\n",
    "addressed?\n",
    "\n",
    "5. Explain, in details, the backpropagation algorithm. What are the limitations of this\n",
    "algorithm?\n",
    "\n",
    "6. Describe, in details, the process of adjusting the interconnection weights in a multi-layer\n",
    "neural network.\n",
    "\n",
    "7. What are the steps in the backpropagation algorithm? Why a multi-layer neural network is\n",
    "required?\n",
    "\n",
    "8. Write short notes on:\n",
    "\n",
    "a. Artificial neuron\n",
    "b. Multi-layer perceptron\n",
    "c. Deep learning\n",
    "d. Learning rate\n",
    "\n",
    "9. Write the difference between:-\n",
    "\n",
    "a. Activation function vs threshold function\n",
    "b. Step function vs sigmoid function\n",
    "c. Single layer vs multi-layer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c89c078",
   "metadata": {},
   "source": [
    "Ans 1:\n",
    "\n",
    "Structure of an artificial neuron: An artificial neuron comprises inputs , weights (associated with each input), a summation function that aggregates the weighted inputs, and an activation function that determines the output based on the aggregated value.\n",
    "\n",
    "Similarity to a biological neuron: Both artificial and biological neurons receive inputs, process them using certain rules (weights and activation thresholds), and produce an output. The basic idea is that they both can be \"activated\" or \"fired\" based on the inputs surpassing a certain threshold.\n",
    "\n",
    "Main components: Inputs, weights, summation function, activation function, and an output.\n",
    "\n",
    "Ans 2:\n",
    "\n",
    "Popular activation functions:\n",
    "Sigmoid function: \n",
    "Outputs values between 0 and 1. Commonly used in the output layer for binary classification tasks.\n",
    "\n",
    "ReLU (Rectified Linear Unit): \n",
    "\n",
    "f(x)=max(0,x) - Outputs the input directly if positive; otherwise, outputs zero. Common in hidden layers due to its efficiency in training deep networks.\n",
    "\n",
    "Tanh function: \n",
    "tanh(x) - Outputs values between -1 and 1. Similar to the sigmoid but symmetric around the origin.\n",
    "\n",
    "Ans 3:\n",
    "a. Rosenblatt’s perceptron model: A perceptron is the simplest form of a neural network, proposed by Frank Rosenblatt in 1957. It consists of a single layer of input neurons with adjustable weights. Data is classified by adjusting weights based on errors during training until a correct decision boundary is found.\n",
    "\n",
    "b. Using the given weights, compute the weighted sum for each data point, apply the activation function, and classify based on the result.\n",
    "\n",
    "c. Multi-layer perceptron (MLP): An MLP consists of an input layer, one or more hidden layers, and an output layer. It can solve the XOR problem by learning non-linear decision boundaries using the hidden layer(s).\n",
    "\n",
    "Ans 4:\n",
    "The learning process involves adjusting synaptic weights based on the error between the network's output and the expected output. The challenge lies in determining the magnitude and direction of weight adjustments. Techniques like gradient descent are employed to navigate the weight space towards optimal values.\n",
    "\n",
    "Ans 5:\n",
    "Backpropagation algorithm: It's a supervised learning algorithm for training neural networks. It calculates the gradient of the loss function with respect to each weight using the chain rule of calculus and adjusts the weights accordingly.\n",
    "\n",
    "Limitations: Can get stuck in local minima, slow convergence in deep networks, and requires labeled data.\n",
    "\n",
    "Ans 6:\n",
    "In a multi-layer neural network, weights are adjusted iteratively using the backpropagation algorithm. For each training example, the error is propagated backward through the network, and weight updates are computed based on the gradients of the loss function.\n",
    "\n",
    "Ans 7:\n",
    "Steps in backpropagation:\n",
    "\n",
    "Forward pass to compute output.\n",
    "Compute the loss/error.\n",
    "Backward pass to compute gradients.\n",
    "Update weights using gradient descent.\n",
    "A multi-layer network is required to capture and learn complex, non-linear relationships in data.\n",
    "\n",
    "Ans 8:\n",
    "a. Artificial neuron: Basic unit in a neural network that processes inputs and produces an output.\n",
    "b. Multi-layer perceptron: A type of neural network with one or more hidden layers.\n",
    "c. Deep learning: Subset of ML using neural networks with many layers.\n",
    "d. Learning rate: A hyperparameter determining the step size during weight updates in training.\n",
    "\n",
    "Ans 9:\n",
    "a. Activation function vs. threshold function: Activation functions determine the output based on the aggregated input, whereas threshold functions produce binary outputs based on a specified threshold.\n",
    "\n",
    "b. Step function vs. sigmoid function: Step function produces a binary output based on a threshold; sigmoid function outputs values between 0 and 1, smoothly transitioning from 0 to 1.\n",
    "\n",
    "c. Single layer vs. multi-layer perceptron: Single-layer perceptrons can only model linearly separable functions; multi-layer perceptrons can model more complex, non-linear functions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5137eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
