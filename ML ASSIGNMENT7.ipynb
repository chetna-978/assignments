{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a96ab60c",
   "metadata": {},
   "source": [
    "1. What is the definition of a target function? In the sense of a real-life example, express the target\n",
    "function. How is a target function&#39;s fitness assessed?\n",
    "2. What are predictive models, and how do they work? What are descriptive types, and how do you\n",
    "use them? Examples of both types of models should be provided. Distinguish between these two\n",
    "forms of models.\n",
    "3. Describe the method of assessing a classification model&#39;s efficiency in detail. Describe the various\n",
    "measurement parameters.\n",
    "4.\n",
    "i. In the sense of machine learning models, what is underfitting? What is the most common\n",
    "reason for underfitting?\n",
    "ii. What does it mean to overfit? When is it going to happen?\n",
    "iii. In the sense of model fitting, explain the bias-variance trade-off.\n",
    "5. Is it possible to boost the efficiency of a learning model? If so, please clarify how.\n",
    "6. How would you rate an unsupervised learning model&#39;s success? What are the most common\n",
    "success indicators for an unsupervised learning model?\n",
    "7. Is it possible to use a classification model for numerical data or a regression model for categorical\n",
    "data with a classification model? Explain your answer.\n",
    "8. Describe the predictive modeling method for numerical values. What distinguishes it from\n",
    "categorical predictive modeling?\n",
    "9. The following data were collected when using a classification model to predict the malignancy of a\n",
    "group of patients&#39; tumors:\n",
    "i. Accurate estimates – 15 cancerous, 75 benign\n",
    "ii. Wrong predictions – 3 cancerous, 7 benign\n",
    "Determine the model&#39;s error rate, sensitivity, precision, and F-measure.\n",
    "10. Make quick notes on:\n",
    "a. The process of holding out\n",
    "b. Cross-validation by tenfold\n",
    "c. Adjusting the parameters\n",
    "11. Define the following terms:\n",
    "a. Purity vs. Silhouette width\n",
    "b. Boosting vs. Bagging\n",
    "c. The eager learner vs. the lazy learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4836cbe",
   "metadata": {},
   "source": [
    "Ans 1:\n",
    "\n",
    "Definition of Target Function: In machine learning, a target function represents the true relationship or mapping between input features and output labels. It defines the desired output for any given input.\n",
    "Real-life Example: In a housing price prediction scenario, the target function would map the features of a house (e.g., size, location, number of rooms) to its actual selling price.\n",
    "Assessing Fitness: The fitness of a target function is assessed by comparing its predictions with actual outcomes using evaluation metrics such as Mean Squared Error (MSE) for regression tasks or accuracy, precision, and recall for classification tasks.\n",
    "\n",
    "Ans 2:\n",
    "\n",
    "Predictive Models: Predictive models aim to make predictions or decisions based on input data to forecast future outcomes. Example: Linear Regression for predicting house prices.\n",
    "Descriptive Models: Descriptive models focus on summarizing or visualizing data to understand patterns or relationships. Example: Clustering algorithms like K-means for segmenting customers based on purchasing behavior.\n",
    "Distinction: Predictive models use historical data to make future predictions, while descriptive models focus on understanding and summarizing existing data patterns.\n",
    "\n",
    "Ans 3:\n",
    "\n",
    "Assessing Classification Model's Efficiency: The efficiency of a classification model is assessed using various metrics:\n",
    "Accuracy: The proportion of correct predictions.\n",
    "Precision: The proportion of true positive predictions among all positive predictions.\n",
    "Recall (Sensitivity): The proportion of true positives correctly identified.\n",
    "F1-Score: The harmonic mean of precision and recall, balancing both metrics.\n",
    "Confusion Matrix: A table showing true positives, true negatives, false positives, and false negatives.\n",
    "\n",
    "Ans 4:\n",
    "\n",
    "i. Underfitting: Occurs when a model is too simple to capture underlying patterns in the data, leading to poor performance on both training and test data.\n",
    "Most Common Reason: Insufficient model complexity or insufficient training data.\n",
    "ii. Overfitting: Occurs when a model is too complex and learns the training data's noise or outliers, resulting in excellent performance on training data but poor generalization to new, unseen data.\n",
    "When it Happens: When the model captures the training data's random fluctuations or outliers.\n",
    "iii. Bias-Variance Trade-off: In model fitting, the bias-variance trade-off refers to the balance between a model's simplicity (bias) and its ability to capture variability (variance) in the data. A model with high bias may underfit the data, while a model with high variance may overfit the data.\n",
    "\n",
    "Ans 5:\n",
    "\n",
    "Boosting Model Efficiency: Yes, the efficiency of a learning model can be boosted by:\n",
    "Ensemble Methods: Combining multiple models to improve prediction accuracy.\n",
    "Feature Engineering: Creating new features or transforming existing ones to enhance model performance.\n",
    "Hyperparameter Tuning: Optimizing model parameters to achieve better results.\n",
    "\n",
    "Ans 6:\n",
    "\n",
    "Rating Unsupervised Learning Model's Success: The success of an unsupervised learning model can be rated based on:\n",
    "Clustering Quality: How well data points within the same cluster are grouped together.\n",
    "Dimensionality Reduction: How effectively the model reduces data dimensions while retaining essential information.\n",
    "Visualization: The ability to visualize complex data structures and patterns.\n",
    "\n",
    "Ans 7:\n",
    "\n",
    "Using Classification/Regression Models: Generally, classification models are used for categorical data, and regression models are used for numerical data. However, with appropriate encoding techniques, it is possible to use classification models for numerical data (e.g., binning) or regression models for categorical data (e.g., logistic regression).\n",
    "\n",
    "Ans 8:\n",
    "\n",
    "Predictive Modeling for Numerical Values: Involves predicting a continuous numerical output based on input features using algorithms like Linear Regression, Random Forest, or Gradient Boosting.\n",
    "Distinction: Numerical predictive modeling focuses on predicting continuous values, while categorical predictive modeling focuses on predicting discrete categories or classes.\n",
    "\n",
    "Ans 9:\n",
    "\n",
    "Error Rate:Total Incorrect Predictions/Total Predictions\n",
    "Sensitivity:True Positives/True Positives+False Negatives\n",
    "Precision:True Positives/True Positives+False Positives\n",
    "F-Measure: Harmonic mean of precision and recall,F1= 2*Precision*Recall/Precision+Recall\n",
    "\n",
    "\n",
    "Ans 10:\n",
    "\n",
    "a. Holding Out: A technique where a subset of the data is reserved for validation or testing purposes, while the rest is used for training.\n",
    "b. Cross-Validation by Tenfold: A resampling technique where the dataset is divided into ten subsets, and the model is trained and validated ten times, each time using a different subset for validation.\n",
    "c. Adjusting Parameters: The process of fine-tuning model hyperparameters to optimize performance, often done using techniques like grid search or random search.\n",
    "\n",
    "Ans 11:\n",
    "\n",
    "a. Purity vs. Silhouette Width:\n",
    "Purity: Measures the degree to which a cluster contains data points from a single class.\n",
    "Silhouette Width: Measures the separation distance between clusters, with higher values indicating better-defined clusters.\n",
    "b. Boosting vs. Bagging:\n",
    "Boosting: An ensemble method that combines multiple weak learners sequentially, with each learner focusing on the mistakes of its predecessor.\n",
    "Bagging: An ensemble method that combines multiple independent models trained on different subsets of the data, with predictions aggregated through averaging or voting.\n",
    "c. Eager Learner vs. Lazy Learner:\n",
    "Eager Learner: A model that builds a generalized model during the training phase and uses it for making predictions without considering the specific training instances.\n",
    "Lazy Learner: A model that delays the learning process until a prediction is needed, often storing all training data and using it for prediction calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464f0f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate: 0.00%\n",
      "Sensitivity (Recall): 100.00%\n",
      "Precision: 100.00%\n",
      "F-measure: 100.00%\n"
     ]
    }
   ],
   "source": [
    "#Ans:9\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Given data\n",
    "true_labels = ['cancerous'] * 15 + ['benign'] * 75\n",
    "predicted_labels = ['cancerous'] * 15 + ['benign'] * 75  # Matching the length to true_labels\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels, labels=['cancerous', 'benign'])\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Calculate metrics\n",
    "error_rate = (fp + fn) / (tp + tn + fp + fn)\n",
    "sensitivity = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "f_measure = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Error Rate: {error_rate:.2%}\")\n",
    "print(f\"Sensitivity (Recall): {sensitivity:.2%}\")\n",
    "print(f\"Precision: {precision:.2%}\")\n",
    "print(f\"F-measure: {f_measure:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8279d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
